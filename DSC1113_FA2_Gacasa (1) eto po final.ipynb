{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pTa18N5XV9L1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from functools import reduce\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "LG8tAdpAWG8B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select only the needed columns\n",
        "data = df[['location', 'date', 'people_fully_vaccinated_per_hundred', 'total_vaccinations']]\n",
        "\n",
        "#Drop rows with missing values in important columns\n",
        "data = data.dropna(subset=['people_fully_vaccinated_per_hundred', 'total_vaccinations'])\n",
        "\n",
        "#Use map to convert 'date' from string to datetime objects\n",
        "#Convert the DataFrame to a list of dicts, then map over each row\n",
        "mapped_data = list(map(\n",
        "    lambda row: {**row, 'date': datetime.strptime(row['date'], \"%Y-%m-%d\")},\n",
        "    data.to_dict(orient='records')\n",
        "))\n",
        "\n",
        "#Get the latest record per country using imperative logic for grouping (not part of map/filter/reduce)\n",
        "#Group by location and keep the last (latest date) entry\n",
        "latest_data = {}\n",
        "for row in mapped_data:\n",
        "    loc = row['location']\n",
        "    if loc not in latest_data or row['date'] > latest_data[loc]['date']:\n",
        "        latest_data[loc] = row\n",
        "\n",
        "latest_records = list(latest_data.values())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3DadtSOKWJAL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use filter to keep only countries where >70% of population is fully vaccinated\n",
        "filtered_data = list(filter(\n",
        "    lambda row: row['people_fully_vaccinated_per_hundred'] > 70,\n",
        "    latest_records\n",
        "))\n",
        "\n",
        "# Step 7: Use reduce to sum total vaccinations across the filtered data\n",
        "total_vaccinations = reduce(\n",
        "    lambda acc, row: acc + float(row['total_vaccinations']),\n",
        "    filtered_data,\n",
        "    0\n",
        ")\n",
        "\n",
        "# Final Output\n",
        "print(\"Total vaccinations in countries with >70% fully vaccinated population:\", int(total_vaccinations))\n",
        "\n",
        "\n",
        "vaccinated_countries = list(map(lambda row: row['location'], filtered_data))\n",
        "print(\"Countries with >70% fully vaccinated population:\", vaccinated_countries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z5e5mvge5Da",
        "outputId": "708724ab-1851-4989-b68d-f0c6e8b9b9be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total vaccinations in countries with >70% fully vaccinated population: 26739296167\n",
            "Countries with >70% fully vaccinated population: ['Argentina', 'Aruba', 'Asia', 'Australia', 'Austria', 'Bahrain', 'Bangladesh', 'Belgium', 'Bermuda', 'Bhutan', 'Brazil', 'Brunei', 'Cambodia', 'Canada', 'Cayman Islands', 'Chile', 'China', 'Colombia', 'Cook Islands', 'Costa Rica', 'Cuba', 'Cyprus', 'Denmark', 'Ecuador', 'England', 'European Union', 'Faeroe Islands', 'Finland', 'France', 'Germany', 'Gibraltar', 'Greece', 'Guernsey', 'High income', 'Hong Kong', 'Iceland', 'Ireland', 'Isle of Man', 'Italy', 'Japan', 'Jersey', 'Kuwait', 'Latvia', 'Liberia', 'Macao', 'Malaysia', 'Maldives', 'Malta', 'Mauritius', 'Monaco', 'Nauru', 'Nepal', 'New Zealand', 'Nicaragua', 'Niue', 'Northern Cyprus', 'Northern Ireland', 'Norway', 'Panama', 'Peru', 'Pitcairn', 'Portugal', 'Qatar', 'Rwanda', 'Samoa', 'San Marino', 'Scotland', 'Seychelles', 'Singapore', 'South America', 'South Korea', 'Spain', 'Sweden', 'Taiwan', 'Thailand', 'Tokelau', 'Tonga', 'Turkmenistan', 'Tuvalu', 'United Arab Emirates', 'United Kingdom', 'Upper middle income', 'Uruguay', 'Vietnam', 'Wales']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this vaccination analysis, I used functional programming instead, and I actually found it cleaner and more efficient.\n",
        "\n",
        "In my code, I used map to convert each country's name into a list. I used a filter to select only the countries where more than 70% of the population was fully vaccinated. Finally, I used reduce to calculate the total number of vaccinations across all of those countries. These functions let me process the data in a more readable and declarative way, without needing to write long loops or worry about manually updating counters.\n",
        "\n",
        "Functional programming works well in data science because we often deal with big datasets that need transforming, filtering, and summarizing. Tools like map, filter, and reduce make these operations easier to write and understand. Plus, they avoid changing variables, so it’s less likely to cause bugs.\n",
        "\n",
        "Even though I’m more comfortable with imperative code, I see how functional programming can help write cleaner, shorter, and safer code—especially for tasks like this, where I just want to transform data from one form to another. What I like about functional programming is that it makes data transformations more readable and faster to write. You just tell the computer what you want done instead of how to do it step by step. It’s especially useful when working with big datasets or building data pipelines. Also, since functions like map and filter don’t change the original data, it’s less likely to introduce bugs."
      ],
      "metadata": {
        "id": "gTxCRpwGYRUE"
      }
    }
  ]
}